{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased-cnndm\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/prophetnet-large-uncased-cnndm\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/teamspace/studios/this_studio/NLP_project/openai_reddit_final.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83797 entries, 0 to 83796\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    83797 non-null  int64 \n",
      " 1   user_id       83797 non-null  object\n",
      " 2   doc_id        83797 non-null  object\n",
      " 3   user_profile  83797 non-null  object\n",
      " 4   post/article  83797 non-null  object\n",
      " 5   summary_text  83797 non-null  object\n",
      " 6   confidence    83797 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ProphetNetTokenizer(name_or_path='microsoft/prophetnet-large-uncased-cnndm', vocab_size=30522, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[SEP]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " ProphetNetForConditionalGeneration(\n",
       "   (prophetnet): ProphetNetModel(\n",
       "     (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "     (encoder): ProphetNetEncoder(\n",
       "       (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "       (position_embeddings): ProphetNetPositionalEmbeddings(512, 1024, padding_idx=0)\n",
       "       (embeddings_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x ProphetNetEncoderLayer(\n",
       "           (self_attn): ProphetNetAttention(\n",
       "             (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (feed_forward): ProphetNetFeedForward(\n",
       "             (activation_fn): GELUActivation()\n",
       "             (intermediate): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "             (output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "           )\n",
       "           (feed_forward_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (decoder): ProphetNetDecoder(\n",
       "       (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "       (position_embeddings): ProphetNetPositionalEmbeddings(512, 1024, padding_idx=0)\n",
       "       (ngram_embeddings): Embedding(2, 1024)\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x ProphetNetDecoderLayer(\n",
       "           (self_attn): ProphetNetNgramSelfAttention(\n",
       "             (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (relative_pos_embeddings): Linear(in_features=1024, out_features=512, bias=True)\n",
       "           )\n",
       "           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (cross_attn): ProphetNetAttention(\n",
       "             (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (cross_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (feed_forward): ProphetNetFeedForward(\n",
       "             (activation_fn): GELUActivation()\n",
       "             (intermediate): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "             (output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "           )\n",
       "           (feed_forward_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (embeddings_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (lm_head): Linear(in_features=1024, out_features=30522, bias=False)\n",
       " ))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['doc_id', 'post/article']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83797 entries, 0 to 83796\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   doc_id        83797 non-null  object\n",
      " 1   post/article  83797 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp = {}\n",
    "\n",
    "for idx , row in data.iterrows():\n",
    "    doc_id = row['doc_id']\n",
    "    text = row['post/article']\n",
    "\n",
    "    if doc_id not in mapp:\n",
    "        mapp[doc_id] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6218"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6218"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(mapp.keys())\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6218"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_texts = list(mapp.values())\n",
    "len(unique_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "\n",
    "def translate_batch(texts):  \n",
    "    inputs = tokenizer(texts, max_length=100, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=512, early_stopping=True)\n",
    "\n",
    "    summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_texts = unique_texts\n",
    "len(src_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(src_texts), batch_size):\n",
    "    batch_texts = src_texts[i:i + batch_size]    \n",
    "    translated_texts = translate_batch(batch_texts)\n",
    "    results.extend(translated_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6218"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_summaries = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp = dict(zip(ids, gen_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6218"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prophetnet_model_summary'] = df['doc_id'].map(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('openai_reddit_final_prophetnet.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/teamspace/studios/this_studio/openai_reddit_final_prophetnet.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
